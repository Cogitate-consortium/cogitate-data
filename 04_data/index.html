<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Data description - Cogitate Data Release</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Data description";
        var mkdocs_page_input_path = "04_data.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Cogitate Data Release
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Welcome to the Cogitate Data Release Documentation</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../01_intro/">Introduction</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../02_subjects/">Subjects</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../03_experiments/">Experiments</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">Data description</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#data-acquisition">Data acquisition</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#file-type-glossary">File type glossary</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#edf-files">EDF files</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#edf-files-eye-tracking">EDF files (Eye-tracking)</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#fif-files">FIF files</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#asc-files">ASC files</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#dicom-files">DICOM files</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#nifti-files">NIFTI files</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#npy-files">NPY files</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../05_acquisition/">Acquisition Modalities</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../06_data_curation/">Data Curation Procedures</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../07_access/">Access COGITATE data</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../08_tutorials/">Tutorials and Examples</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../09_next/">Next steps</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../10_support/">Support</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../11_appendix/">Appendix</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Cogitate Data Release</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a> &raquo;</li>
      <li class="breadcrumb-item active">Data description</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="data-description">Data description</h1>
<h2 id="data-acquisition">Data acquisition</h2>
<p>Although our data collection had a specific purpose, the data we gathered holds potential value for a range of diverse inquiries. Consequently, the COGITATE consortium has chosen to openly share all raw data collected, with the aim of facilitating its utilization for various research endeavors and promoting data reusability. This approach reflects our commitment to contributing to the broader scientific community.</p>
<p>We have made available two primary formats for the data acquired during the experimental phase of the COGITATE project, specifically from Experiment 1:</p>
<p><strong>1. Unprocessed Data:</strong></p>
<p>The unprocessed data format closely resembles the original acquired data, having undergone minimal processing to ensure compliance with GDPR/HIPAA anonymity standards.</p>
<p><strong>2. BIDS FormatÂ (Brain Imaging Data Structure):</strong></p>
<p>BIDS format, widely adopted in cognitive neuroscience, enhances data reusability. To facilitate others in leveraging our data, we have released it in BIDS format. The conversion scripts employed to transform the raw data into BIDS format can be accessed via this link: [LINK].</p>
<p>We emphasize our explicit intent to share the entirety of our data, empowering the community to integrate it into their research. When utilizing the data, it is important to consider the contextual factors and limitations that may affect its interpretation.</p>
<p>Release format and Modality Table:</p>
<table>
<thead>
<tr>
<th>Release format -&gt; <br> ___ <br> Modality</th>
<th>Raw / Unprocessed</th>
<th>Bids converted</th>
<th>Bids derivatives / Pre-processed</th>
<th>Additionally processed</th>
</tr>
</thead>
<tbody>
<tr>
<td>Eye Tracking &amp; Behavioral data</td>
<td>EDF</td>
<td>EDF</td>
<td>ASC</td>
<td>ASC</td>
</tr>
<tr>
<td>fMRI</td>
<td>DICOM</td>
<td>DICOM</td>
<td>NIFTI</td>
<td>NIFTI</td>
</tr>
<tr>
<td>MEEG</td>
<td>FIF</td>
<td>FIF</td>
<td>NPY</td>
<td>NPY</td>
</tr>
<tr>
<td>iEEG/ECoG</td>
<td>EDF</td>
<td>EDF</td>
<td>EDF</td>
<td>EDF</td>
</tr>
</tbody>
</table>
<h2 id="file-type-glossary">File type glossary</h2>
<h3 id="edf-files">EDF files</h3>
<p>EDF files, also known as European Data Format files, are a standardized file format used for storing and exchanging time-series biological and physiological data. EDF files are commonly used in medical and scientific research contexts to record and analyze data from various types of measurements, such as electroencephalography (EEG), electrocardiography (ECG), electromyography (EMG), and other bioelectrical signals.</p>
<p>EDF files are designed to accommodate data from multiple channels, allowing researchers to store and manage data collected simultaneously from different sensors or electrodes. The format supports both raw signal data and associated metadata, including information about sampling rates, units of measurement, patient demographics, and recording conditions.</p>
<p>One of the key advantages of the EDF format is its portability and compatibility across different software and platforms. Many data analysis and visualization tools in the field of neuroscience and medicine support the EDF format, enabling researchers to share and collaborate on data without compatibility issues.</p>
<p>It's worth noting that there are variations and extensions of the EDF format, such as EDF+ and EDF/EDF+ Converter, which provide additional features and improvements for specific applications. Overall, EDF files play an essential role in the storage and analysis of physiological and biological data in scientific and medical research.</p>
<h3 id="edf-files-eye-tracking">EDF files (Eye-tracking)</h3>
<p>EDF (EyeLink Data Format) is a file format used to store eye-tracking data collected during experiments using the EyeLink system. It plays a crucial role in the analysis of visual attention and gaze behavior in various research fields like psychology, cognitive science, human-computer interaction, to name a few. EDF files store data collected from eye-tracking experiments, which typically involve recording where a participant's eyes are fixating and how they move while viewing a stimulus, such as images or text.</p>
<p>The EyeLink system, developed by SR Research Ltd., is a widely used eye-tracking hardware and software solution. The EyeLink system records various types of data during an experiment, including the position of the participant's gaze (where they are looking on the screen) and the timing of their eye movements. This data is then saved in EDF files, which have a specific structure that allows the analysis and interpretation of eye-tracking data using specialized software.
EDF files contain information such as timestamps, gaze coordinates, pupil size, and information about the visual stimuli being presented. These files can be used to analyze patterns of visual attention, fixations (periods when the eyes are relatively stationary), saccades (rapid eye movements between fixations), and other eye movement behaviors.
To work with EDF files, typically software is provided by SR Research or other third-party tools that can read and interpret the data in these files. This software allows researchers to visualize eye movement patterns, conduct statistical analyses, and draw conclusions about how participants process visual information.</p>
<h3 id="fif-files">FIF files</h3>
<p>FIF files in MEEG (Magnetoencephalography and Electroencephalography) refer to the File Format for the Input and Output of MEG and EEG data. MEG and EEG are neuroimaging techniques used to study brain activity. FIF files are a standardized format developed by the MNE (Magnetoencephalography and Electroencephalography) community to store and exchange MEG and EEG data.</p>
<p>FIF files contain various types of information related to neuroimaging data, including:</p>
<ol>
<li>Raw sensor data: MEG and EEG measurements recorded from sensors placed on the scalp or near the head.</li>
<li>Event information: Time-stamped triggers or markers indicating the timing of events, such as stimulus presentations or subject responses.</li>
<li>Sensor locations and orientations: Information about the physical positions and orientations of sensors used in the measurements.</li>
<li>Head geometry: Information about the shape and structure of the subject's head, which is crucial for accurate source localization.</li>
<li>Covariance matrices: Statistical information about the relationships between sensor measurements at different time points or frequencies.</li>
<li>Anatomical MRI data: High-resolution structural images of the subject's brain, used for source localization and spatial alignment.</li>
</ol>
<p>The FIF file format ensures compatibility and interoperability between different MEG and EEG software tools and facilitates data sharing and collaboration in the neuroimaging research community. It's worth noting that MEG and EEG data can be quite complex and multidimensional, and the FIF format provides a structured and standardized way to store and manage this data.</p>
<h3 id="asc-files">ASC files</h3>
<p>ASC files in the context of eye tracking refer to data files generated by eye tracking systems, which are used to record and analyze eye movement and gaze behavior. These files contain valuable information about a person's visual attention, including where they are looking, how long they are looking at certain areas, and how their gaze moves across a screen or a visual stimulus.</p>
<p>ASC files typically store a time-stamped sequence of gaze data points, which include information such as:</p>
<ol>
<li>Timestamps: The exact time at which each gaze data point was recorded.</li>
<li>Gaze Coordinates: The x and y coordinates on the screen where the person's gaze is directed.</li>
<li>Pupil Diameter: The size of the person's pupil, which can provide insights into changes in visual processing or cognitive load.</li>
<li>Fixations: Periods of stable gaze where the person is looking at a specific point without significant movement.</li>
<li>Saccades: Rapid eye movements between fixations, indicating shifts in attention.</li>
<li>Blinks: Instances when the person's eyes are closed, which can be important for data cleaning and analysis.</li>
</ol>
<p>Researchers and usability professionals use ASC files to study various aspects of human visual attention and cognitive processes. Eye tracking studies can provide insights into user behavior when interacting with websites, advertisements, software interfaces, or other visual stimuli. By analyzing ASC files, researchers can better understand how people engage with visual information, make decisions, and process visual content.</p>
<p>Software tools and programming libraries are often used to process and analyze ASC files, extracting meaningful patterns and insights from the raw gaze data. These insights can be used to optimize user interfaces, design effective visual communication, and improve user experiences in various applications.</p>
<h3 id="dicom-files">DICOM files</h3>
<p>DICOM (Digital Imaging and Communications in Medicine) files are a standard format used for storing, transmitting, and managing medical images and related information. They are widely used in the field of radiology and other medical imaging specialties, such as MRI (Magnetic Resonance Imaging), CT (Computed Tomography), ultrasound, and more.</p>
<p>DICOM files are designed to ensure interoperability and compatibility among different imaging devices, picture archiving and communication systems (PACS), and other healthcare information systems. These files contain not only the actual image data but also metadata and contextual information, such as patient information, image acquisition parameters, study details, and more. This comprehensive set of information allows medical professionals to accurately interpret and diagnose medical images, track patient history, and collaborate effectively across different healthcare facilities.</p>
<p>DICOM files typically have a ".dcm" file extension and adhere to a specific structure and data format defined by the DICOM standard. This standardization facilitates seamless exchange of medical images and data between different software and hardware platforms, contributing to improved patient care and medical research.</p>
<h3 id="nifti-files">NIFTI files</h3>
<p>NIFTI (Neuroimaging Informatics Technology Initiative) files are a widely used file format in the field of neuroimaging, particularly in the context of functional and structural magnetic resonance imaging (MRI) data. These files store three-dimensional brain images and related metadata, allowing researchers and clinicians to store, share, and analyze neuroimaging data.</p>
<p>NIFTI files typically have the ".nii" or ".nii.gz" file extensions. The ".nii" format is uncompressed, while the ".nii.gz" format is compressed using gzip compression. These files contain information about the image dimensions, voxel sizes, data type (e.g., integer or floating-point values), and other relevant information.</p>
<p>NIFTI was developed as an improvement over the earlier Analyze file format. It addresses certain limitations of the Analyze format, such as the ability to handle 3D and 4D data (3D data over time), improved support for different data types, and better compatibility with modern software tools.</p>
<p>Researchers and medical professionals use NIFTI files to store various types of neuroimaging data, including structural Â MRI scans, functional MRI scans, and diffusion tensor imaging (DTI) data (which captures white matter tracts and connectivity patterns within the brain).</p>
<p>NIFTI files are supported by many neuroimaging software packages, making them a crucial part of the neuroimaging data analysis workflow. Researchers can use these files for tasks such as preprocessing, visualization, statistical analysis, and creating anatomical atlases.</p>
<h3 id="npy-files">NPY files</h3>
<p>NPY files, short for "NumPy files," are a file format used in the Python programming language for storing and exchanging numerical data. NumPy is a popular library in Python that provides support for multi-dimensional arrays and matrices, along with various mathematical functions to operate on these arrays.</p>
<p>NPY files are specifically used to save and load arrays and data structures created using NumPy. These files have the extension ".npy" and are binary files that efficiently store the data in a format that preserves the array's shape, data type, and other metadata. This makes them suitable for fast and efficient storage and retrieval of large numerical datasets, which is especially useful in scientific computing, data analysis, and machine learning applications.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../03_experiments/" class="btn btn-neutral float-left" title="Experiments"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../05_acquisition/" class="btn btn-neutral float-right" title="Acquisition Modalities">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../03_experiments/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../05_acquisition/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
